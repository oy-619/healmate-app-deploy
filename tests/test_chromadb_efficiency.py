"""
ChromaDBåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š
1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãæ©Ÿèƒ½
2. å·®åˆ†æŠ½å‡ºæ©Ÿèƒ½
3. ChromaDBã®åˆæœŸåŒ–ãƒ»æ›´æ–°æ©Ÿèƒ½
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import os
import sys
import json
import tempfile
import shutil
from datetime import datetime
from unittest.mock import Mock, patch

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(project_root, "src"))

# ãƒ†ã‚¹ãƒˆç”¨ã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEST_DIR = os.path.join(tempfile.gettempdir(), "test_chromadb_efficiency")
TEST_METADATA_FILE = os.path.join(TEST_DIR, "test_metadata.json")


def setup_test_environment():
    """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    if os.path.exists(TEST_DIR):
        shutil.rmtree(TEST_DIR)
    os.makedirs(TEST_DIR, exist_ok=True)
    print(f"âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {TEST_DIR}")


def cleanup_test_environment():
    """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    if os.path.exists(TEST_DIR):
        shutil.rmtree(TEST_DIR)
    print("ğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")


def test_metadata_functions():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿æ›¸ãæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜é–¢æ•°
    def save_test_metadata(message_count, last_update=None):
        if last_update is None:
            last_update = datetime.now().isoformat()

        metadata = {"message_count": message_count, "last_update": last_update}

        with open(TEST_METADATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°
    def load_test_metadata():
        if os.path.exists(TEST_METADATA_FILE):
            try:
                with open(TEST_METADATA_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return {"message_count": 0, "last_update": None}
        return {"message_count": 0, "last_update": None}

    # ãƒ†ã‚¹ãƒˆ1: æ–°è¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    save_test_metadata(100)
    metadata = load_test_metadata()
    assert metadata['message_count'] == 100, "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã«å¤±æ•—"
    assert metadata['last_update'] is not None, "æ›´æ–°æ—¥æ™‚ã®ä¿å­˜ã«å¤±æ•—"
    print("  âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿: æˆåŠŸ")

    # ãƒ†ã‚¹ãƒˆ2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
    save_test_metadata(150)
    updated_metadata = load_test_metadata()
    assert updated_metadata['message_count'] == 150, "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã«å¤±æ•—"
    print("  âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°: æˆåŠŸ")

    # ãƒ†ã‚¹ãƒˆ3: å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    os.remove(TEST_METADATA_FILE)
    default_metadata = load_test_metadata()
    assert default_metadata['message_count'] == 0, "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—"
    print("  âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å‡¦ç†: æˆåŠŸ")


def test_message_id_generation():
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDç”Ÿæˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ†” ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDç”Ÿæˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    # ãƒ¢ãƒƒã‚¯Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
    class MockDocument:
        def __init__(self, content, metadata):
            self.page_content = content
            self.metadata = metadata

    def get_message_ids_from_docs_test(docs):
        ids = set()
        for doc in docs:
            content = doc.page_content
            metadata = doc.metadata
            msg_id = (
                f"{metadata.get('date', '')}_{metadata.get('time', '')}_{content[:50]}"
            )
            ids.add(msg_id)
        return ids

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    test_docs = [
        MockDocument(
            "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­", {"date": "2025/10/17", "time": "10:00"}
        ),
        MockDocument("ãŠç–²ã‚Œã•ã¾ã§ã™", {"date": "2025/10/17", "time": "18:00"}),
        MockDocument(
            "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­", {"date": "2025/10/17", "time": "10:00"}
        ),  # é‡è¤‡
    ]

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    ids = get_message_ids_from_docs_test(test_docs)

    # æ¤œè¨¼
    assert len(ids) == 2, f"é‡è¤‡æ’é™¤ã«å¤±æ•—: æœŸå¾…å€¤2, å®Ÿéš›{len(ids)}"
    expected_id1 = "2025/10/17_10:00_ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­"
    expected_id2 = "2025/10/17_18:00_ãŠç–²ã‚Œã•ã¾ã§ã™"
    assert expected_id1 in ids, "IDç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã«å•é¡Œ"
    assert expected_id2 in ids, "IDç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã«å•é¡Œ"

    print("  âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDç”Ÿæˆ: æˆåŠŸ")
    print("  âœ… é‡è¤‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è­˜åˆ¥: æˆåŠŸ")


def test_diff_extraction():
    """å·®åˆ†æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” å·®åˆ†æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    # ãƒ¢ãƒƒã‚¯Documentã¨DBã®ä½œæˆ
    class MockDocument:
        def __init__(self, content, metadata):
            self.page_content = content
            self.metadata = metadata

    class MockDB:
        def __init__(self, existing_docs):
            self.existing_docs = existing_docs

        def get(self):
            if not self.existing_docs:
                return {'documents': [], 'metadatas': []}

            documents = [doc.page_content for doc in self.existing_docs]
            metadatas = [doc.metadata for doc in self.existing_docs]
            return {'documents': documents, 'metadatas': metadatas}

    def get_new_messages_only_test(current_docs, existing_db=None):
        if existing_db is None:
            return current_docs

        try:
            existing_docs = existing_db.get()
            if not existing_docs or not existing_docs.get('documents'):
                return current_docs

            existing_ids = set()
            existing_contents = existing_docs.get('documents', [])
            existing_metadatas = existing_docs.get('metadatas', [])

            for i, content in enumerate(existing_contents):
                metadata = existing_metadatas[i] if i < len(existing_metadatas) else {}
                msg_id = f"{metadata.get('date', '')}_{metadata.get('time', '')}_{content[:50]}"
                existing_ids.add(msg_id)

            new_docs = []
            for doc in current_docs:
                content = doc.page_content
                metadata = doc.metadata
                msg_id = f"{metadata.get('date', '')}_{metadata.get('time', '')}_{content[:50]}"

                if msg_id not in existing_ids:
                    new_docs.append(doc)

            return new_docs

        except Exception as e:
            print(f"å·®åˆ†æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {str(e)}ã€‚å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return current_docs

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿
    existing_docs = [
        MockDocument("æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1", {"date": "2025/10/16", "time": "10:00"}),
        MockDocument("æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2", {"date": "2025/10/16", "time": "15:00"}),
    ]

    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢å­˜ + æ–°è¦ï¼‰
    current_docs = [
        MockDocument(
            "æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1", {"date": "2025/10/16", "time": "10:00"}
        ),  # æ—¢å­˜
        MockDocument(
            "æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2", {"date": "2025/10/16", "time": "15:00"}
        ),  # æ—¢å­˜
        MockDocument(
            "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1", {"date": "2025/10/17", "time": "09:00"}
        ),  # æ–°è¦
        MockDocument(
            "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2", {"date": "2025/10/17", "time": "12:00"}
        ),  # æ–°è¦
    ]

    # ãƒ¢ãƒƒã‚¯DBã®ä½œæˆ
    mock_db = MockDB(existing_docs)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    new_messages = get_new_messages_only_test(current_docs, mock_db)

    # æ¤œè¨¼
    assert len(new_messages) == 2, f"å·®åˆ†æŠ½å‡ºã«å¤±æ•—: æœŸå¾…å€¤2, å®Ÿéš›{len(new_messages)}"
    new_contents = [doc.page_content for doc in new_messages]
    assert "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1" in new_contents, "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1ãŒæŠ½å‡ºã•ã‚Œã¦ã„ãªã„"
    assert "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2" in new_contents, "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸2ãŒæŠ½å‡ºã•ã‚Œã¦ã„ãªã„"
    assert "æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1" not in new_contents, "æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒèª¤ã£ã¦æŠ½å‡ºã•ã‚Œã¦ã„ã‚‹"

    print("  âœ… å·®åˆ†æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯: æˆåŠŸ")
    print("  âœ… æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç‰¹å®š: æˆåŠŸ")
    print("  âœ… æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é™¤å¤–: æˆåŠŸ")


def test_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    # ãƒ†ã‚¹ãƒˆ1: ä¸æ­£ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    invalid_json_file = os.path.join(TEST_DIR, "invalid.json")
    with open(invalid_json_file, 'w') as f:
        f.write("invalid json content")

    def load_metadata_with_error_handling(file_path):
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return {"message_count": 0, "last_update": None}
        return {"message_count": 0, "last_update": None}

    result = load_metadata_with_error_handling(invalid_json_file)
    assert result == {"message_count": 0, "last_update": None}, "ä¸æ­£JSONå‡¦ç†ã«å¤±æ•—"
    print("  âœ… ä¸æ­£JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†: æˆåŠŸ")

    # ãƒ†ã‚¹ãƒˆ2: å­˜åœ¨ã—ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®æ›¸ãè¾¼ã¿
    def safe_save_metadata(file_path, data):
        try:
            dir_path = os.path.dirname(file_path)
            os.makedirs(dir_path, exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—: {str(e)}")
            return False

    nonexistent_path = os.path.join(TEST_DIR, "nonexistent", "metadata.json")
    test_data = {"message_count": 50, "last_update": datetime.now().isoformat()}

    result = safe_save_metadata(nonexistent_path, test_data)
    assert result == True, "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã‚’ä¼´ã†ä¿å­˜ã«å¤±æ•—"
    assert os.path.exists(nonexistent_path), "ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ãªã„"
    print("  âœ… å­˜åœ¨ã—ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®æ›¸ãè¾¼ã¿: æˆåŠŸ")


def test_integration():
    """çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”— çµ±åˆãƒ†ã‚¹ãƒˆã®é–‹å§‹...")

    # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’æ¨¡æ“¬ã—ãŸãƒ†ã‚¹ãƒˆ
    metadata_file = os.path.join(TEST_DIR, "integration_metadata.json")

    def simulate_initial_setup():
        """åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        # åˆå›ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ä¿å­˜
        initial_messages = [
            {
                "content": f"åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}",
                "date": "2025/10/16",
                "time": f"{10+i}:00",
            }
            for i in range(5)
        ]

        metadata = {
            "message_count": len(initial_messages),
            "last_update": datetime.now().isoformat(),
        }

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        return initial_messages

    def simulate_diff_update():
        """å·®åˆ†æ›´æ–°ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        # æ—¢å­˜ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open(metadata_file, 'r', encoding='utf-8') as f:
            existing_metadata = json.load(f)

        # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        new_messages = [
            {"content": f"æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}", "date": "2025/10/17", "time": f"{9+i}:00"}
            for i in range(3)
        ]

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        total_count = existing_metadata["message_count"] + len(new_messages)
        updated_metadata = {
            "message_count": total_count,
            "last_update": datetime.now().isoformat(),
        }

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(updated_metadata, f, ensure_ascii=False, indent=2)

        return new_messages, total_count

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    initial_messages = simulate_initial_setup()
    assert len(initial_messages) == 5, "åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—"
    print("  âœ… åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: æˆåŠŸ")

    new_messages, total_count = simulate_diff_update()
    assert len(new_messages) == 3, "å·®åˆ†æ›´æ–°ã«å¤±æ•—"
    assert total_count == 8, "ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã®è¨ˆç®—ã«å¤±æ•—"
    print("  âœ… å·®åˆ†æ›´æ–°: æˆåŠŸ")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    with open(metadata_file, 'r', encoding='utf-8') as f:
        final_metadata = json.load(f)

    assert final_metadata["message_count"] == 8, "æœ€çµ‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«èª¤ã‚Š"
    print("  âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§: æˆåŠŸ")


def run_all_tests():
    """å…¨ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("ğŸš€ ChromaDBåŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)

    setup_test_environment()

    try:
        test_metadata_functions()
        test_message_id_generation()
        test_diff_extraction()
        test_error_handling()
        test_integration()

        print("\n" + "=" * 50)
        print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†: å…¨ã¦æˆåŠŸ!")
        print("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ©Ÿèƒ½: æ­£å¸¸å‹•ä½œ")
        print("âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDç”Ÿæˆ: æ­£å¸¸å‹•ä½œ")
        print("âœ… å·®åˆ†æŠ½å‡ºæ©Ÿèƒ½: æ­£å¸¸å‹•ä½œ")
        print("âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: æ­£å¸¸å‹•ä½œ")
        print("âœ… çµ±åˆæ©Ÿèƒ½: æ­£å¸¸å‹•ä½œ")

        print("\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print("  - åˆå›DBä½œæˆ: å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ä¿å­˜ãŒæ­£å¸¸ã«å‹•ä½œ")
        print("  - å·®åˆ†æ›´æ–°: æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿æŠ½å‡ºãŒæ­£å¸¸ã«å‹•ä½œ")
        print("  - ã‚³ã‚¹ãƒˆåŠ¹ç‡: é‡è¤‡å‡¦ç†ã®æ’é™¤ãŒæ­£å¸¸ã«å‹•ä½œ")
        print("  - ã‚¨ãƒ©ãƒ¼å‡¦ç†: ç•°å¸¸æ™‚ã®é©åˆ‡ãªå‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œ")

        return True

    except AssertionError as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return False
    except Exception as e:
        print(f"\nğŸ’¥ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False
    finally:
        cleanup_test_environment()


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
